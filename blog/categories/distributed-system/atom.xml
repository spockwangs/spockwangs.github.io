<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Distributed System | Spockwang's Blog]]></title>
  <link href="http://spockwangs.github.io/blog/categories/distributed-system/atom.xml" rel="self"/>
  <link href="http://spockwangs.github.io/"/>
  <updated>2019-01-09T13:27:54+08:00</updated>
  <id>http://spockwangs.github.io/</id>
  <author>
    <name><![CDATA[spockwang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Paper Review: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage With COPS]]></title>
    <link href="http://spockwangs.github.io/blog/2019/01/08/paper-review-cops/"/>
    <updated>2019-01-08T13:04:46+08:00</updated>
    <id>http://spockwangs.github.io/blog/2019/01/08/paper-review-cops</id>
    <content type="html"><![CDATA[<p>这篇<a href="https://www.cs.cmu.edu/~dga/papers/cops-sosp2011.pdf">论文</a>描述了如何设计保证因果一致性又不牺牲
可用性的分布式存储系统。与传统的强调可用性的分布式系统相比，因果一致性模型对程序员更加友好，又不牺牲
性能。
<!-- more --></p>

<h3 id="lamport">为什么要在Lamport时钟后附加节点标示符使写入操作的版本号全局唯一？</h3>

<p>不唯一会导致两个问题：</p>

<ol>
  <li>跟踪的依赖不准确，在复制到其它集群时判断依赖是否已经满足时会导致误判：依赖还未写入时会误以为已经
写入。</li>
  <li>无法解决并发写数据时的冲突，由于Lamport时钟不是全序，导致在解决并发冲突时计算最终结果时时不确定的，
这样会导致数据继续分叉。</li>
</ol>

<h3 id="cops-gt">为什么COPS-GT需要存储完整的依赖而不是从直接依赖计算出完整的依赖？</h3>

<p>一个依赖包含key和version，每个key只会存储最近一段时间的version及其直接依赖，所以直接依赖的version可
能已经不存在了，也就无法计算出完整的依赖。</p>

<p>举个例子，假如存有如下数据：
<code>
&lt;key=a, version=1, deps=[&lt;key=b, version=1&gt;]&gt;
&lt;key=c, version=1, deps=[&lt;key=a, version=1&gt;]&gt;
</code>
数据c直接依赖a，间接依赖b。然后a更新了同时删除其旧版本：
<code>
&lt;key=a, version=2, deps=[]&gt;
&lt;key=c, version=1, deps=[&lt;key=a, version=1&gt;]&gt;
</code>
数据c依然依赖a，但是我们却丢失c对b的依赖信息。</p>

<h3 id="section">数据中心之间同步时如何保证依赖得到满足？</h3>

<p>论文中没有详述，但我想是这样，在消费复制队列时检查依赖在本地是否满足，若没有满足则等待一段时间重试。
没满足的依赖肯定在队列的后面，等待应该是异步的，否则阻塞了队列的消费会导致依赖永远不会被满足。为了优
化这里的重试，消费队列的节点可以跟踪没有满足的依赖，每当消费一个队列元素时则更新这个依赖关系，一旦满
足了条件就立即重试。</p>

<p>另外一种解决办法是操作的发送方在写入消息队列时按依赖的拓扑顺序写入，消费端也按序消费，这样就不用检查
依赖关系了。不过这会导致发送方逻辑变得复杂，而且也会导致消费端吞吐量下降。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Paper Review: Google Dapper]]></title>
    <link href="http://spockwangs.github.io/blog/2018/08/20/paper-review-google-dapper/"/>
    <updated>2018-08-20T00:00:00+08:00</updated>
    <id>http://spockwangs.github.io/blog/2018/08/20/paper-review-google-dapper</id>
    <content type="html"><![CDATA[<p>本文对Google的论文”<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf">Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</a>“的总结，这篇论文描述了Google的分布式跟踪系统Dapper.</p>

<!-- more -->

<h1 id="introduction">Introduction</h1>

<p>现代的互联网服务通常都是实现为复杂的大规模分布式系统，由许多分布在不同机器上的模块组成，这些模块可能
是不同团队用不同编程语言开发的。开发一个工具用于帮助理解这个系统的行为、诊断性能问题是很有价值的。
Dapper就是Google开发的这样一个分布式系统跟踪工具。</p>

<p>考虑一个例子：web搜索引擎。前端服务会将一个搜索请求分发到许多查询服务器，每个查询服务器负责检索本地
的索引分区。这个查询还会被分发到其它子系统处理诸如广告、拼写检查之类的工作。最后，所有这些服务的结果
汇总成一个搜索结果页面。为了完成一个搜索查询需要许多机器协调工作，而且搜索对延迟是很敏感的。仅仅查看
整体的耗时只能知道存在性能问题，但是无法知道是哪个服务导致的，也不知道原因。对于一个搜索查询，工程师
并不知道有哪些服务在处理，因为系统在不断增加新服务。而且有很多服务是不同团队负责的，工程师无法知道每
个服务的内部细节。很多服务会共享机器，所以性能问题也有可能是同机部署的其它服务导致的。</p>

<p>根据上述例子我们可以发现分布式跟踪系统在空间上必须无所不在，在时间上持续监控。这就导致如下三个需求：
- 低开销：跟踪系统必须对服务有几乎可忽略的影响。
- 对应用开发者透明：开发者不需要关注这个跟踪系统。如果还需要开发者来介入，必然会导致遗漏。
- 可伸缩性：能够应对大规模的分布式系统。</p>

<p>另外，跟踪数据从产生到可以分析的延迟要足够短。</p>

<h1 id="dapper">Dapper的系统设计</h1>

<p>分布式跟踪必须记录一次请求发起到处理完成的整个过程。一个有用的信息必须包括请求的唯一标识和每个服务器
发送和接收消息的时间戳。</p>

<p><img src="/images/dapper_figure_1.png"></p>

<p>有两种方法可以将一次请求涉及到的所有服务的信息聚合起来：
1. 黑盒：仅需要每个服务的消息记录，然后使用统计学模型推断消息之间的关联关系。
2. 基于注解：每个消息都用一个全局唯一的标识符标记以便与请求关联起来。</p>

<p>黑盒方法尽管可移植性更好，但是需要更多的数据才会有足够的正确性。基于注解的方法的主要缺点就是要对程序
进行修改，但是由于Google的服务都是用的统一的代码库实现RPC、控制流，所以只需要对这些代码库进行修改即
可，对服务开发者是透明的。</p>

<h2 id="trace-trees-and-spans">Trace trees and spans</h2>

<p>一次请求的跟踪可以看成一颗树，每个节点对应一个服务称为span. 边表示服务的上下游关系。每个span都有一个
trace id, span id和parent span id. trace id用于唯一标识一个请求，span id用于唯一标识一个span. parent
span id用于标记span的上游。这些ID都是64位的随机数。</p>

<p><img src="/images/dapper_figure_2.png"></p>

<p>span记录了消息的开始和结束时间以及其它事件时间和服务开发者提供的相关注解信息。注意：span的数据可能来
自多个机器。比如，一个RPC span包含了客户端和服务端的信息。</p>

<p><img src="/images/dapper_figure_3.png"></p>

<h2 id="intrumentation-points">Intrumentation points</h2>

<p>Dapper通过修改公共库来实现应用透明，主要集中在三点：
- 线程模型，每个线程使用私有存储保存trace上下文.
- 异步控制流保证每个回调函数能正确处理trace.
- RPC库负责将trace id和span id传递给下游.</p>

<h2 id="annotations">Annotations</h2>

<p>除了修改框架自动产生跟踪数据外，Dapper也提供API允许服务开发者添加应用相关的信息方便调试。为了防止添
加过多的数据，每个span都会限制数据大小。</p>

<h2 id="trace">Trace的搜集</h2>

<p>Trace的搜集有3步：(1) span数据写入本地文件, (2) Dapper从每个机器上读取数据然后(3)写入Bigtable.
一个trace就是Bigtable的一行，trace id是key，每一列一个span. 数据从产生到写入存储的中位数耗时是15秒。</p>

<p><img src="/images/dapper_figure_5.png"></p>

<p>从上面的描述我们可以看出trace的搜集是分开进行的（每个机器只负责记录本机的信息，而不是搜集下游的信息一起记录），原因有2个：
1. 搜集下游的信息会导致响应过大，特别是对根节点服务。
2. 不是所有的请求都是嵌套的，有些请求是异步的，下游在处理完之前会先发送响应给上游。</p>

<h2 id="section">安全和隐私</h2>

<p>有些场景对安全和隐私很敏感，记录RPC的数据会暴露安全风险。所以Dapper仅存储RPC的名字，不记录其中的数据。
不过Dapper提供一些选项让开发者自行决定是否记录一些有用的数据。</p>

<p>通过跟踪安全协议参数，Dapper可以监控服务是否满足安全政策的要求。</p>

<h1 id="section-1">性能优化</h1>

<p>Dapper对性能的影响有3点：trace的生成，trace的搜集和Dapper对生产服务的影响。</p>

<p>生成trace的成本主要是创建和销毁span以及写入磁盘。trace的注解也会产生额外的开销，不过只有在trace被采
样的时候。将span写入磁盘是开销最大的，通过批量写入和异步写入大大减少了对应用服务的影响。但是写入操作
仍然会对高吞吐的应用产生一定的影响。</p>

<p>在生产服务器上搜集trace数据也会影响生产服务进程。我们通过限制Dapper进程的调度优先级减小对CPU的竞争。
Dapper进程也会消耗少量的网络带宽（不到0.01%）。</p>

<p>为了评估Dapper进程对生产服务造成的影响，我们使用搜索集群作为例子来测量Dapper对平均耗时和吞吐量的影响。</p>

<p><img src="/images/dapper_table_2.png"></p>

<p>虽然对吞吐量的影响很小，但为了避免对耗时产生影响，跟踪数据的采样还是有必要的。采用更低的采样频率可以
让跟踪数据保留的时间更长些，给Dapper搜集服务更多时间。高吞吐量的服务采用更低的采样频率可以有效降低开
销，而且由于事件发生的频率足够高，降低采样频率也会捕获到这些事件。但是对于低吞吐量的服务就必须提高采
样频率了。所以，采样频率应该能够自适应。实际使用的采样频率与跟踪数据一起记录下来，方便分析工具据此统
计跟踪频率。</p>

<p>上述的采样是为了减小生成跟踪数据时对应用程序产生影响。Dapper还需要控制写入存储的数据量，以减小成本和
降低对BigTable的写入带宽。所以还需要第二轮采样，在搜集跟踪数据时计算trace id的hash值<code>z</code>($0 \leq z \leq
1$)，如果小于设置的采样比例就写入Bigtable，否则就丢弃。由于在不同的机器上一次请求的trace id是相同的，
这种方法能保证要么保留一个trace的所有数据，要么全部丢弃，不会只保留一部分的情况。</p>

<h1 id="dapper-1">Dapper工具设计</h1>

<p>Dapper提供了API和web界面用于分析跟踪数据。提供的API主要有以下这些：
- 根据trace id访问
- 批量访问：指定时间窗口访问所有的trace
- 根据索引查询：支持按服务名、机器和时间戳的联合索引查询。</p>

<h1 id="section-2">使用经验</h1>

<ul>
  <li>开发时使用Dapper，表现在以下方面：
    <ul>
      <li>优化性能：Dapper有助于找出优化点。比如可以找出不必要的串行请求，特别是这些可能是其他人开发的子系统
发起的。</li>
      <li>正确性：观察服务之间的调用关系判断请求的下游是否正确。</li>
      <li>帮助理解系统行为</li>
      <li>测试</li>
    </ul>
  </li>
  <li>解决长尾耗时
    <ul>
      <li>调试大型分布式系统的耗时问题是很困难的，因为很难重现。调试必须先建立假设，然后再通过数据来验证或
推翻假设来定位原因，这需要不断试错。Dapper提供的数据有助于快速验证试错，提高调试效率。</li>
    </ul>
  </li>
  <li>监控服务网络流量
    <ul>
      <li>网络监控工具可以发现异常的网络流量，但是却无法找到原因，而Dapper有助于这一点。</li>
    </ul>
  </li>
  <li>监控共享资源的消耗情况
    <ul>
      <li>许多不同的业务都会依赖共享的存储服务（比如Bigtable，GFS，Chubby等），仅从这些服务来看很来知道请
求的最终来源，也不知道不同业务对其资源的消耗情况。Dapper可以将整个请求处理栈汇集起来，有助于了解
共享资源是被谁使用的。</li>
    </ul>
  </li>
</ul>

<h1 id="conclusion">Conclusion</h1>

<p>Dapper相当于是分布式版本的<code>gstack</code>，可以查看分布式系统的调用栈，帮助理解系统行为，诊断性能瓶颈。在实
际使用过程中取得了良好的效果，也有以下一些局限性需要优化。
- 对批处理的支持：Dapper假设一次只处理一个跟踪的请求，如果将多个请求合并起来处理将无法区分。
- 对离线负载的支持：Dapper是设计来跟踪在线服务的。跟踪离线负载入MapReduce任务时需要将trace id跟某个
  工作单元联系起来。
- 诊断根因：Dapper有助于找出有问题的服务，但是不足于发现根本原因。
- 记录内核级别的信息：这有时候方便找出根因。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式系统的分区管理]]></title>
    <link href="http://spockwangs.github.io/blog/2018/01/03/cluster-membership-protocol/"/>
    <updated>2018-01-03T00:00:00+08:00</updated>
    <id>http://spockwangs.github.io/blog/2018/01/03/cluster-membership-protocol</id>
    <content type="html"><![CDATA[<p>当数据量大到单机存不下时就需要分布式存储系统。分布式存储与单机存储最大的区别就是把数据按一定规则切分
为多个部分，每个机器只存储其中一部分，这样理论上来讲分布式存储可以应付无穷大的数据量。但是这里带来一
个新的问题，即如何找到我需要的数据是存储在哪台机器呢？这就是分布式系统的分区管理模块需要解决的问题，
除了这个问题外，还需要解决负载均衡和容灾的问题。</p>

<p>分区管理是有一定成本的，随机器数量增加而增加，所以分布式存储的伸缩性不是无穷的，伸缩能力主要取决于
分区管理。所以分区管理是分布式系统中相当重要的模块。</p>

<p>本文将介绍分区管理的一般解决思路，并介绍实际的分布式系统的解决方案，最后总结不同需求场景下应采用的
解决方案。
<!--more--></p>

<h2 id="section">分区管理应该解决的问题</h2>

<p>分区管理主要解决以下问题：</p>

<ol>
  <li>分区，如何将数据集且分为多个分区？</li>
  <li>路由
    <ol>
      <li>如何找到分区所在节点？</li>
      <li>如何保证路由信息的一致性？比如，如何解决客户端缓存的过期路由信息？如果读写请求因为过期的路由信息
由错误的节点处理，可能导致数据丢失。</li>
    </ol>
  </li>
  <li>容灾
    <ol>
      <li>如何检测节点的失败？</li>
      <li>节点失败多种多样，基本可分为两种情况：短暂的失败和长期失败。短暂的失败可能是由于临时过载处理不
及时导致的，长期失败可能是硬件故障导致的，短期无法恢复。针对这两种失败应采用不同的容灾策略。</li>
    </ol>
  </li>
</ol>

<h2 id="section-1">分区</h2>

<p>数据通常都有唯一标识，也就是key，所以我们可以根据key来切分数据，通常有以下的切分方案：</p>

<ul>
  <li>根据key的范围来划分
    <ul>
      <li>优点：可执行按范围查询</li>
      <li>缺点：可能分布不均匀，可以结合时间戳或者数据来源进一步分区来缓解</li>
    </ul>
  </li>
  <li>根据key的hash来划分
    <ul>
      <li>优点：hash可将不均匀的key转换为均匀的数字，所以分布是均匀的</li>
      <li>缺点：只能精确查找，无法按范围查询。不过可以设计聪明的hash算法来执行模糊匹配，比如GeoHash可用来
查询附近的地理位置。</li>
      <li>例子：一致性hash</li>
    </ul>
  </li>
</ul>

<h2 id="section-2">路由</h2>

<h3 id="section-3">路由策略</h3>

<p>路由要解决的问题是讲分区映射到节点上，通常需要考虑以下几个需求：</p>

<ol>
  <li>分区尽量均匀分布到节点上；</li>
  <li>在进行负载均衡操作时，分区仍然是可用的；</li>
  <li>负载均衡时移动的数据量尽量少.</li>
</ol>

<p>一种容易想到的映射方案是将分区hash对节点数量取模，这种分区方案严重依赖节点的数量。当节点数量变化时，所有
分区到节点的映射都要发生变化，不满足上述的第3点要求，所以不建议使用。</p>

<p>常见的路由策略有两种：</p>

<ol>
  <li>查表
    <ul>
      <li>分区到节点的映射存储在一张表里</li>
    </ul>
  </li>
  <li>伪随机算法
    <ul>
      <li>分区到节点的映射通过一个伪随机算法计算，如Ceph的CRUSH算法。</li>
      <li>优点：路由信息的空间复杂度只跟节点数量有关，存储空间小</li>
    </ul>
  </li>
</ol>

<h3 id="section-4">路由信息的一致性</h3>

<p>另一个问题是如何保证路由信息的一致性：如果读写请求由于过期的路由信息发送到错误的节点，轻则导致读到
错误的数据（比如请求的key不是由该节点负责，所以该节点返回找不到这个key，其实系统中是有这个key的），
重则导致数据写到错误的节点上，最终数据被丢弃。</p>

<p>权威的路由信息一定会存储在某些节点上，根据存储节点的不同可分为一些两种：</p>

<ol>
  <li>中心化路由
    <ul>
      <li>路由信息储存在某些特殊的节点上，他们构成路由层，专门转发客户端的路由请求.</li>
      <li>例如，GFS的路由信息存储在主节点上；BigTable的路由信息由Chubby服务来维护；MongoDB的客户端请求由
路由节点转发，其路由信息由一组配置服务器维护；Ceph的路由信息由一组Monitor节点维护，Monitor集群采
用Paxos协议保证路由信息的一致性和可靠性。</li>
    </ul>
  </li>
  <li>去中心化路由
    <ul>
      <li>每个节点都存储路由信息的一部分或全部，由所有节点共同维护，他们之间通过一种复制协议（比如Gossip
协议）来保证一致性，所有节点均可路由客户端请求。</li>
      <li>最典型的例子就是Dynamo，所有节点存储了完整的路由信息，通过Gossip协议保证路由信息的最终一致。
 Cassandra, CouchDB, Voldemort和Redis Cluster也采用了类似的方案。</li>
    </ul>
  </li>
</ol>

<p>采用去中心化路由的好处是更好的可用性，任何节点均可单独转发客户端请求。若采用中心化的方式，路由层若发生
故障将导致系统不可用，例如BigTable的可用性将直接受到Chubby的限制，而Dynamo就没有此问题，除非其所有节点
均不可用（BigTable的可用性不超过4个9，而Dynamo的可用性可达到5个9）。</p>

<p>不管采用哪种路由存储方式，均无法保证客户端路由信息与系统的完全一致。当客户端从系统获取到路由信息后到
访问数据这段时间，路由信息此时可能已经发生了变化（节点的状态随时可能变化）。为了容灾，数据的分布必须
随节点状态的变化而变化，不可能在客户端访问数据期间将路由信息锁定起来，因而不能严格保证客户端的路由信息
与系统完全一致。我们只要能保证在客户端的路由信息错误时能够纠正即可。一般采用如下两种方式来解决这个问题：</p>

<ul>
  <li>数据节点具有其自身负责的分区的权威信息。若客户端请求的key不由其负责，则返回路由错误给客户端，由其
重新刷新路由信息重试（如BigTable）；或者数据节点有完整的路由信息，直接将其请求转发给正确的节点
（如Dynamo）.</li>
  <li>数据节点与其它节点发生网络分区了，导致其负责的分区信息本身已经过时，而客户端的路由信息与其刚好一致，
此时数据节点无法判断客户端的路由错误。为了防止这种情况的发生，在新节点接管该节点的分区前必须保证旧节点
不再处理客户端的请求。例如，Ceph和BigTable都采用租约机制来保证旧节点一定不会处理客户端的请求。</li>
</ul>

<p>还有些系统本身是容忍部分数据丢失的，因而也没有机制保证客户端路由信息的一致性，比如Redis Cluster，当
客户端访问的数据节点与其它节点发生网络分区时（此时客户端和数据节点的路由信息都是旧的并可能相同）
会依然接受读写请求，直到它检测到了网络分区为止，这段时间写的数据将在主节点迁移后丢失。</p>

<h3 id="section-5">路由转发</h3>

<p>路由的转发直接影响到请求处理的延迟，转发次数过多会导致延迟过高，而且延迟也不稳定。转发方式可分为3种：</p>

<ol>
  <li>客户端直接转发
    <ul>
      <li>客户端可缓存或预取路由信息，此后将直接路由请求给正确的节点，可最大程度减少转发次数。即使路由信息
过期也可以通过系统的转发纠正。</li>
      <li>客户端逻辑会比较复杂，通常这部分逻辑会以客户端库的形式由系统提供，编译链接到应用程序。</li>
    </ul>
  </li>
  <li>路由层转发
    <ul>
      <li>如果由于某种场景限制无法使用客户端库，可由负载均衡器来实现路由功能.</li>
    </ul>
  </li>
  <li>数据节点转发
    <ul>
      <li>对于采用去中心化的路由存储可由数据节点转发.</li>
    </ul>
  </li>
</ol>

<p>一般来讲，路由转发的策略与路由一致性的解决方案有关，中心化的路由一般可支持客户端转发和路由层转发，去
中心化的路由可支持以上3种，比如Voldemort可配置以上3种方案。</p>

<h2 id="section-6">容灾</h2>

<p>容灾的第一步是检测失败节点，不管是什么检测算法都需要发送心跳，所以检测的通信模式将直接制约系统的可伸缩
性。根据心跳的通信模式分为3种：</p>

<ol>
  <li>星形模式
    <ul>
      <li>主节点定期发送心跳给数据节点，数据节点也可发送心跳给主节点</li>
      <li>例子：GFS, BigTable, ElasticSearch</li>
    </ul>
  </li>
  <li>全连通模式
    <ul>
      <li>所有节点相互之间发送心跳</li>
      <li>例子：Dynamo, Cassandra, Redis Cluster</li>
    </ul>
  </li>
  <li>分组模式
    <ul>
      <li>仅某个分区的副本节点之间发送心跳</li>
      <li>例子：Ceph, MongoDB</li>
    </ul>
  </li>
</ol>

<p>很明显，星形模式对主节点的负担比较重，可伸缩性完全由主节点制约。全连通模式的通信量比较大，伸缩性也会
有所限制，但是其可用性比较好，因为所有节点均可作为备胎用于数据迁移，只要有一个节点可用，整个系统就可用。
分组模式的伸缩性是最好的，节点数的增多不会引起通信量增加，同时若其数据可在整个集群间迁移，其可用性也
非常好。</p>

<p>大多数系统的失败检测是周期性运行的，不过Dynamo和Cassandra的失败检测是客户端驱动的，因此检测算法的触发
方式分两种：</p>

<ol>
  <li>周期性触发
    <ul>
      <li>大多数系统是这种</li>
    </ul>
  </li>
  <li>客户端驱动
    <ul>
      <li>Dynamo和Cassandra</li>
    </ul>
  </li>
</ol>

<p>节点失败的原因有很多，有些是短暂的，有些是永久的，检测算法一般无法区分这两者，所以在处理失败时必须有
所权衡，既不能太敏感也不能过于迟钝，否则会导致失败处理不及时或者系统不稳定。所以检测到失败后还必须权
衡失败的性质然后再处理。有的系统是用中心化的方式来判断失败的性质，有些是用去中心化的方式，所以基本可
分为两种：</p>

<ol>
  <li>中心化检测
    <ul>
      <li>检测结果上报到某个节点或者监控集群进行全局性判断是否需要进行数据迁移.</li>
      <li>GFS, BigTable, Ceph, ElasticSearch, Redis Cluster</li>
    </ul>
  </li>
  <li>去中心化检测
    <ul>
      <li>本地自行判断，由于缺乏全局信息，仅可处理短暂失败，长期失败需要人工干预.</li>
      <li>Dynamo, Cassandra</li>
    </ul>
  </li>
</ol>

<p>对于短暂失败一般通过重试或者hinted handoff解决。永久性失败必须迁移数据。有些系统需要人为干预来迁移，
比如Dynamo和Cassandra.</p>

<h2 id="section-7">案例介绍</h2>

<p>本节将重点介绍几个著名的分布式系统的实际例子，它们对许多系统的设计都有很大影响，了解这几个系统的设计
方案将有助于了解其它系统，也可在自己设计系统时参考。</p>

<h3 id="gfs">GFS</h3>

<p>GFS是Google设计的分布式文件系统，将多个机器的硬盘抽象成了一个硬盘。由一个主节点、多个数据节点和客户端
库组成。主节点负责维护全局的路由信息，并检测数据节点的状态。数据节点负责数据的可靠存储。客户端负责读写
请求，从主节点拉取路由信息。</p>

<p>由于只需要根据文件名来查找所以采用Hash分区。并采用动态路由策略。路由信息采用中心化方式，便于全局协调。
节点的状态监测采用星形通信模式和中心化监测机制。很容易看出，单一的主节点是容量瓶颈和系统的风险点。后来
Google增加了主节点的冷备来防止单点风险，但是仍然解决不了容量问题。之所以采用这样的中心化架构就是因为
实现简单。</p>

<h3 id="bigtable">BigTable</h3>

<p>GFS存储的是非结构化数据，不方便查询。BigTable是基于GFS设计的结构化存储系统，支持列式数据模型。其架构
类似于GFS，包括一个主节点、多个数据节点和客户端库。主节点负责维护全局路由信息，它存储在Chubby上，并
周期性检测数据节点的状态。数据节点负责客户端的读写请求，而数据是存储在GFS。</p>

<p>由于需要支持按范围查询，所以采用范围分区方案。分区的大小可根据数据量动态调整，拆分或合并。与GFS一样采用
中心化路由。为了保证路由信息的一致性，必须保证任意时刻每个分区只有一个数据节点可访问，BigTable用租约
机制来保证这一点（基于Chubby的带超时的锁）。数据节点的状态由主节点周期性检测，若失败则调整路由信息由
新节点来接管之前的分区。</p>

<p>虽然主节点只有一个，但并不会过于影响可用性，因为客户端的访问路径并不经过主节点，而是从Chubby获取路由
信息。主节点只是负责检测数据节点的状态、负载均衡等。但是如果主节点长期故障将影响可用性。</p>

<h3 id="dynamo">Dynamo</h3>

<p>Dynamo是Amazon设计的用于存储用户购物车的分布式存储系统，主要强调可用性。所以其设计思路与以上两个系统
有很大的区别。它是一个完全去中心化的架构，所有节点都是数据节点，角色完全对称，不存在特殊的节点。客户端
可访问任何节点进行读写，只要有一个节点存活则整个系统就是可用的。</p>

<p>由于不需要按范围查询并为了保证数据分布均匀，采用hash分区。为了保证路由信息变化时数据迁移量尽量小，采用
一致性Hash方案。所有节点存储全局的路由信息，并通过Gossip协议维护最终一致性。所有节点相互之间检测状态，
由客户端驱动，本地化决策，可容忍短暂的失败。长期的节点失败由人工干预解决。</p>

<p>正是由于采用了完全去中心化的架构，其可用性达到了惊人的5个9.</p>

<h3 id="cassandra">Cassandra</h3>

<p>Cassandra是Facebook开发的高可用存储系统，用于其消息搜索。它结合了BigTable的数据模型和Dynamo的分区管
理方案，也是一个完全去中心化的架构。与Dynamo相比，只是在一致性hash和多版本冲突解决等细节上有区别。</p>

<h3 id="ceph">Ceph</h3>

<p>Ceph也是一个分布式文件系统，强调伸缩性。由客户端库、一小组Monitor集群和许多OSD组成。Monitor集群维护全局的
OSD拓扑结构，在节点失败时调整拓扑结构。Monitor集群运行Paxos协议来保证拓扑结构的一致性和可靠性。Monitor集群的
拓扑结构信息通过类似Gossip的协议传递给所有OSD。OSD负责数据存储及复制，处理读写请求，相互之间检测心跳
状态，并在节点失败时迁移数据等。</p>

<p>由于只需要支持精确查找，Ceph采用按hash分区。分区大小不可自动调整，但可以人工增加。Ceph最具创新的地方
是其路由算法，跟其它系统不同的是，分区到节点的映射不是查表而是伪随机算法CRUSH计算出来的，具有以下特点：</p>

<ol>
  <li>根据key、拓扑结构和分配规则即可算出节点地址；</li>
  <li>确定性：相同的输入产生相同的输出；</li>
  <li>一定程度上保证分区的分布是均匀的，并可考虑到节点的网络层次结构；</li>
  <li>当拓扑结构发生变化时数据迁移量很小。</li>
</ol>

<p>由于CRUSH算法的支持，路由信息只需要存储拓扑结构就可以了，其存储空间只与OSD的数量有关，而与分区数量无关，
大大减小了需要的存储量，有助于伸缩性的实现。</p>

<p>与BigTable类似，Ceph采用租约机制保证路由信息的一致性。</p>

<p>Ceph的心跳检测是分组模式，即保存同一分区的OSD之间发送心跳，当发现节点失败时请求Monitor集群更新拓扑结构
重新分布数据。分组模式有助于减小通行量，增加了伸缩性。同时为了减小Monitor集群的负载，更新拓扑结构的请求
会合并批量上报给Monitor集群。</p>

<p>与GFS相比，Ceph提高伸缩性的策略有：</p>

<ol>
  <li>分区的粒度更粗，路由信息更小，增加了系统容量
    <ul>
      <li>GFS的分区粒度是文件，Ceph的一个分区可存储多个文件，粒度由分区的数量决定，这样有助于减小路由信息，
使得中心化的路由节点可支持更多数据。</li>
      <li>Ceph采用CRUSH算法计算路由信息，进一步压缩了路由信息。</li>
    </ul>
  </li>
  <li>路由信息扩散至所有数据节点，可以让数据节点承担更多工作（包括数据复制、失败检测及恢复、负载均衡），
减轻Monitor集群的压力
    <ul>
      <li>GFS的路由信息仅存储在主节点，导致许多管理工作只能由主节点来负责，成为性能瓶颈。</li>
    </ul>
  </li>
</ol>

<h2 id="conclusion">Conclusion</h2>

<p>综合以上几个例子可以看出，设计分布式系统基本有两种思路：中心化和去中心化架构。中心化架构比较简单，容
易实现，而且由于有全局信息便于全局协调，包括数据分布、负载均衡、数据迁移等。为了防止中心节点成为性能
瓶颈，通常将控制逻辑和数据逻辑分离，只有控制逻辑经过中心节点，而数据逻辑尽量直接与数据节点通信。比如，
尽量让客户端缓存路由信息，防止每次都要访问中心节点。Ceph是一个极好的案例，尽量让数据节点分担管理工作，
有助于高伸缩性的实现。完全的去中心化架构任何模块都没有单点风险，拥有极好的可用性，但是实现比较复杂，
因此很少系统采用。由于其节点的功能是对称的，所以负载分布也较为均匀，没有节点会因为承担更多的工作而成
为性能瓶颈，可伸缩性也很好。</p>

<p>设计分布式系统时一个重要的考虑是CAP理论，其中P代表分区容忍性，这个是世界的现实，无法绕过去，所以只能
在一致性和可用性之间进行权衡。强调可用性的系统可参考Dynamo的解决方案，采用去中心化的架构。而强调一致
性的系统则建议采用中心化架构，因为一致性必然涉及到多个节点的协调，若维护有一个全局信息将更方便进行协
调。</p>

<h2 id="references">References</h2>

<ul>
  <li>The Google File System</li>
  <li>Ceph: A Scalable, High-Performance Distributed File System</li>
  <li>Dynamo: Amazon’s Highly Available Key-value Store</li>
  <li>Cassandra - A Decentralized Structured Storage System</li>
  <li>RADOS: A Scalable, Reliable Storage Service for Petabyte-scale Storage Clusters</li>
  <li>Bigtable: A Distributed Storage System for Structured Data</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Feature Flags进行并行开发和持续集成]]></title>
    <link href="http://spockwangs.github.io/blog/2014/09/03/using-feature-flags-enable-concurrent-dev/"/>
    <updated>2014-09-03T00:00:00+08:00</updated>
    <id>http://spockwangs.github.io/blog/2014/09/03/using-feature-flags-enable-concurrent-dev</id>
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>在服务开发过程中经常需要一边修复线上bug，一边又要开发新特性，而且可能需要同时开发好几个新特性，不同
的新特性开发持续的时间不等。这样要等到所有代码都开发完、测试好需要很长时间，代码一直处于无法上线的状
态，无法敏捷响应需求。如果这时候线上又出现紧急bug，就没法及时发布修复。
<!--more--></p>

<h2 id="feature-branch">使用feature branch的解决方案</h2>

<p>为了防止修复bug和特性开发不相互干扰，并能及时响应线上bug，一般采用源代码版本管理系统的分支功能：</p>

<ul>
  <li>trunk分支是经过严格测试的稳定分支，随时处于发布状态，并与线上代码一致；</li>
  <li>每个特性可以另开一个branch开发，等到稳定后再合入trunk发布；</li>
  <li>修复bug时也开一个branch开发，验证通过后再合入trunk发布。</li>
</ul>

<p>笔者采用这种传统的解决方案使用了一段时间，确实可以解决并行开发的问题，但是在实践中也发现了一些恼火的
问题：</p>

<ul>
  <li>一个潜在的风险是合入trunk，多个特性单独测试是ok的，一旦合入就容易引起bug，所以合入trunk后还得继续
测试；</li>
  <li>SVN操作比较复杂：建立分支，开发，合并trunk的更新，反向合入trunk，测试，提交trunk，删除branch。对于
新手来讲更容易出错，尤其是多人开发时需要解决冲突，严重影响效率。</li>
</ul>

<h2 id="feature-flag">使用feature flag</h2>

<p>要解决SVN操作复杂的问题就必须停止使用branch开发，只使用trunk。但是trunk又必须保持随时可以发布的状态。
这可以借助于灰度发布的思想解决，新特性若没开发完毕可以使其代码不生效，用户看不见，待到成熟后再上线，
这可以采用开关控制其是否上线，就像一个个模块一样，可要可不要。</p>

<p>我们可以为每个特性取一个名字，在配置文件中控制其是否上线：</p>

<pre><code>use-new-feature=true
</code></pre>

<p>然后在代码中这样判断：</p>

<pre><code>if (config-&gt;isFeatureLaunched("use-new-feature")) {
    // 新特性代码。
    ...
}
</code></pre>

<p>更进一步，开关出了打开和关闭这两种状态外还可以引入中间状态，进行灰度测试：</p>

<pre><code>use-new-feature=10%
</code></pre>

<p>意思是说对于10%的用户使用新特性，灰度测试新特性是否正常。并且在某些情况下如果出了紧急问题可以先用开
关关掉，提供有损服务。</p>

<p>引入feature flag后我们完全可以换个角度去看待特性开发。每个特性可以看成一个个独立的模块，可以上线也可
以下线，可从技术角度和业务角度决定是否上线，更好地降低了特性之间的耦合。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用MySql实现事务型消息队列]]></title>
    <link href="http://spockwangs.github.io/blog/2014/06/19/implement-transactional-queue-using-mysql/"/>
    <updated>2014-06-19T00:00:00+08:00</updated>
    <id>http://spockwangs.github.io/blog/2014/06/19/implement-transactional-queue-using-mysql</id>
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>在离线数据处理系统中，为了解除模块之间的耦合关系，往往需要消息队列来实现模块之间的通信。对于离线系统来讲，消息队列要满足以下要求：</p>

<ul>
  <li>消息不能丢失，即使在系统失败的情况下。消息一旦被插入就一定会被至少处理一次（只被处理一次是最好的，但是实现起来有难度，所以只要求at-least-once semantic）；</li>
  <li>FIFO顺序；</li>
  <li>支持多生产者；</li>
  <li>支持多消费者。每个消息只能被其中一个消费者处理。
<!--more--></li>
</ul>

<h2 id="section">第一次尝试</h2>

<p>为了满足事务特性，最简单的做法就是用MySql数据库来实现这个队列。为了支持FIFO顺序，可以用MySql的自增ID来排序，先进入的消息ID要小些。MySql数据库是支持并发操作的，这就自动支持了多生产者的情况。为了支持多消费者并且每个消息只被一个消费者处理，可以为每个消费者分配一个ID，当某个消息正在被消费者处理时，这个消费者就被认为是这个消息的owner。</p>

<p>根据以上思路，构造表如下：</p>

<pre><code>CREATE TABLE message_queue (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  
  -- owner为NULL时表示消息未被处理；否则正在被某个消费者处理，其值就是这个消费者的ID
  owner VARBINARY(255),
  message VARBINARY(255) NOT NULL
);
</code></pre>

<p>其中<code>message</code>是跟业务相关的消息数据，可以是一个字段也可以是多个字段。那么enqueue操作如下：</p>

<pre><code>insert into message_queue (message) values ('a message');
</code></pre>

<p>dequeue操作有点复杂，分3步：</p>

<ol>
  <li>
    <p>获取未被处理的消息。先占有这些消息，设置owner。为了加快速度减少访问数据库的频率，可以批量操作；</p>

    <pre><code> update message_queue set owner='me' where owner is null limit 10;
</code></pre>

    <p>根据<a href="http://dev.mysql.com/doc/refman/5.0/en/mysql-affected-rows.html"><code>mysql_affected_rows()</code></a>的返回结果可以判断是否有未被处理的消息。若有，则取出消息：</p>

    <pre><code> select message from message_queue where owner='me';
</code></pre>

    <p>注意，<code>update</code>操作是根据自增ID的顺序操作的，这就实现了FIFO。若把这两步合并成一个事务执行会造成对表的锁占用过多时间（多了一个请求响应来回时间）。</p>
  </li>
  <li>处理消息，此时表不会被锁住，其它消费者也可以获取消息；</li>
  <li>
    <p>处理完毕后从数据库中删除。对于处理出错的消息可以根据业务要求重试、忽略或者插入消息队列待下次再处理。</p>

    <pre><code> delete from message_queue where owner='me'
</code></pre>
  </li>
</ol>

<p>上面没有考虑失败的情况。如果某个消费者在第1步和第2步之间失败的话，一个被占用的消息可能永远不会再被处理，即使此时有其它消费者还在运行，这就不满足at-least-once的要求了。</p>

<h2 id="section-1">考虑消费者失败的情况</h2>

<p>为了解决考虑消费者失败的情况，一个比较简单的方法就是对消费者进行监控（比如采用心跳），一旦失败就将其占有的但是还未删除的消息的<code>owner</code>设置成<code>null</code>。但是由谁来监控呢？容易想到的方法可能是单独建立一个服务对每个消费者进行监控，不过对于我们这里的简单问题不需要这么复杂，而且我本人不喜欢这种主从不对称的解决方案（毕竟谁来监控这个监控服务呢？）。我们可以让消费者相互监控。</p>

<p>每当消费者取消息时，如果发现有消息虽然被占用但是却长时间没有处理完毕，那么就认为该消息的<code>owner</code>失败了，这个消息就可以被占用。为了判断消息处理是否超时，增加一个字段表示该消息被处理的时间戳：</p>

<pre><code>CREATE TABLE message_queue (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  
  -- owner为NULL时表示消息未被处理；否则正在被某个消费者处理，其值就是这个消费者的ID
  owner VARBINARY(255),
  
  -- 最近一次被owner取出的时间
  dequeued_time DATETIME,
  message VARBINARY(255) NOT NULL
);
</code></pre>

<p><code>dequeue</code>的第1步的update操作改为如下（假设消息处理的耗时不超过60s）：</p>

<pre><code>update message_queue set owner='me',dequeued_time=NOW() 
    where owner is null or dequeued_time &lt; SUBTIME(NOW(), SEC_TO_TIME(60)) limit 10;
</code></pre>

<p>这样即使消费者A在第1步和第2步之间失败了，消费者B还可以重新取出该消息重新处理。所以只要还有消费者在，消息至少会被处理一次。</p>

<h2 id="section-2">如何实现只处理一次呢？</h2>

<p>如果消费者在第2步和第3步之间失败的话，这个消息就会被再次取出来处理一次，这样就一共处理了2次。要保证每个消息只被处理一次，也就是要保证第2步和第3步是一个原子操作，要么都做，要么都不做。换句话说，第2步和第3步要合并成一个事务操作，但是这两步涉及到的是两个不同的实体（一个视业务逻辑而定，一个是MySql数据库），用事务处理的概念来讲就是两个不同的resource manager，必须采用分布式事务协议（比如两步提交协议）才能实现事务语义，这已远超出本文的范围了，不在这里赘述。</p>

<h2 id="see-also">See also</h2>

<ul>
  <li><a href="https://blog.engineyard.com/2011/5-subtle-ways-youre-using-mysql-as-a-queue-and-why-itll-bite-you/">5-subtle-ways-youre-using-mysql-as-a-queue-and-why-itll-bite-you</a></li>
  <li><a href="https://www.rabbitmq.com/">RabbitMQ</a>是一个消息队列解决方案，毕竟用数据库实现只是权宜之计</li>
</ul>
]]></content>
  </entry>
  
</feed>
